{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189aaed7",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://oepfelbaum.com/wp_live/wp-content/themes/appletree/dist/img/logo-main_ed18093c87353e6715bcc40c699c37f9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4162625",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Oe LuKB Market Risk - Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a278a2",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "source": [
    "**Author**: Fabian Arter <br>\n",
    "**Date**: 2022-01-29 - 2022-05-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa255e21",
   "metadata": {},
   "source": [
    "The aim of this notebook is the explain the main concepts of market risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38389884",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Volatility & Return Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e601811",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Input:</b> Please choose here for which titles you would like to see historical data. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad0c44",
   "metadata": {},
   "source": [
    "   Check **Yahoo Finance** for all tickers: [https://finance.yahoo.com](https://finance.yahoo.com/lookup) \n",
    "\n",
    "Enter in the below `data.frame` the desired tickers (incl. a friendly name, which can be chosen by you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "828a40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.tickers.df = data.frame(ticker=c(\"ROG.SW\", \n",
    "                                       \"NESN.SW\", \n",
    "                                       \"NOVN.SW\", \n",
    "                                       \"^SSMI\"),\n",
    "                               friendly.name=c(\"Roche\", \n",
    "                                               \"Nestle\", \n",
    "                                               \"Novartis\", \n",
    "                                               \"SMI\")\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e402767",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Input:</b> Please choose here the start and end date of the historical price data. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff873632",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.date = as.Date(\"2010-01-01\")\n",
    "last.date  = Sys.Date() # today "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6623a256",
   "metadata": {
    "tags": [
     "hide_input",
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker friendly.name\n",
      "1  ROG.SW         Roche\n",
      "2 NESN.SW        Nestle\n",
      "3 NOVN.SW      Novartis\n",
      "4   ^SSMI           SMI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "start date: 2010-01-01\n",
      "last date:  2022-05-08\n"
     ]
    }
   ],
   "source": [
    "print(input.tickers.df)\n",
    "message(paste(\"start date:\",start.date))\n",
    "message(paste(\"last date: \",last.date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f482f3e",
   "metadata": {},
   "source": [
    "### Variance vs Volatility\n",
    "The variance indicates the risk of an asset or of an entire portfolio, it is the standard deviation $\\sigma$ (volatility) of returns squared $\\sigma^2$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d6e10",
   "metadata": {},
   "source": [
    "### Volatility of a portfolio\n",
    "The risk of a portfolio can be quantified by computing the variance of the portfolio return, which is equal to $w^T\\Sigma w$ where $w$ is the already introduced weight vector and the $\\Sigma$ is the covariance matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534bee2",
   "metadata": {},
   "source": [
    "### Volatility: Codes Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2e729",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ggplot2\")\n",
    "install.packages(\"BatchGetSymbols\")\n",
    "install.packages(\"dplyr\")\n",
    "install.packages(\"reshape2\")\n",
    "library(ggplot2)\n",
    "library(BatchGetSymbols)\n",
    "library(dplyr)\n",
    "\n",
    "#' etlFinData\n",
    "#'\n",
    "#' @param start.date Start Date of the historical price data\n",
    "#' @param end.date  End Date of the historical price data\n",
    "#' @param input.tickers.df Data Frame with the products we wish to have the prices, this includes the ticker symbol and a friendly name\n",
    "#' @return a list with two data frames: cumulated.returns.data.long and cumulated.returns.data.long\n",
    "#' @export\n",
    "etlFinData <- function(start.date=as.Date(\"2018-01-01\"), \n",
    "                       last.date =Sys.Date(),\n",
    "                       input.tickers.df = data.frame(ticker=c(\"LUKN.SW\",\"AIR.PA\"),\n",
    "                                                     friendly.name=c(\"LUKN.SW\",\"AIRBUS\"))\n",
    ") {\n",
    "  \n",
    "  # load data via BatchGetSymbols\n",
    "  daily.returns.data.long <- BatchGetSymbols::BatchGetSymbols(\n",
    "    tickers      = as.character(input.tickers.df$ticker),\n",
    "    first.date   = start.date,\n",
    "    last.date    = last.date,\n",
    "    freq.data    = \"daily\",\n",
    "    type.return  = \"log\",\n",
    "    cache.folder = file.path(tempdir(), 'BGS_Cache') )$df.tickers\n",
    "  \n",
    "  \n",
    "  # add friendly names\n",
    "  daily.returns.data.long <-  merge(daily.returns.data.long, input.tickers.df, by=\"ticker\")\n",
    "  \n",
    "  daily.returns.data.long[is.na(daily.returns.data.long$ret.adjusted.prices),]$ret.adjusted.prices <- 0\n",
    "  daily.returns.data.long <- na.omit(daily.returns.data.long)\n",
    "  \n",
    "  daily.returns.data.long <- data.frame(ref.date        = daily.returns.data.long$ref.date,\n",
    "                                        friendly.name   = as.character(daily.returns.data.long$friendly.name),\n",
    "                                        price.adjusted  = daily.returns.data.long$price.adjusted,\n",
    "                                        daily.return    = daily.returns.data.long$ret.adjusted.prices)\n",
    "  \n",
    "  daily.returns.data.wide <- reshape2::dcast(daily.returns.data.long,  ref.date ~ friendly.name, value.var = \"daily.return\")\n",
    "  daily.returns.data.wide <- na.omit(daily.returns.data.wide)\n",
    "  \n",
    "  # cumulated returns wide\n",
    "  cumulated.returns.data.wide  <- if(nrow(input.tickers.df) !=1) {\n",
    "    as.data.frame(cbind(ref.date = daily.returns.data.wide$ref.date, apply(daily.returns.data.wide[,2:ncol(daily.returns.data.wide)], 2, cumsum)))\n",
    "    \n",
    "  }\n",
    "    \n",
    "\n",
    "  # cumulated returns long\n",
    "  cumulated.returns.data.long <- if(nrow(input.tickers.df) !=1) {\n",
    "    cumulated.returns.data.long               <- reshape2::melt(cumulated.returns.data.wide, id.vars=1, measure.vars = 2:ncol(cumulated.returns.data.wide))\n",
    "    cumulated.returns.data.long$ref.date      <- as.Date(cumulated.returns.data.long$ref.date, origin = \"1970-01-01\")\n",
    "    cumulated.returns.data.long$name          <- as.character(cumulated.returns.data.long$variable) ; cumulated.returns.data.long$variable <- NULL\n",
    "    cumulated.returns.data.long$cumul.return  <- cumulated.returns.data.long$value ; cumulated.returns.data.long$value <- NULL\n",
    "    cumulated.returns.data.long\n",
    "  } else {\n",
    "    data.frame(ref.date = daily.returns.data.long$ref.date, name = daily.returns.data.long$friendly.name, cumul.return=cumsum(daily.returns.data.long$daily.return))\n",
    "  }\n",
    "  \n",
    "  cumulated.returns.data.wide$ref.date      <- as.Date(as.numeric(cumulated.returns.data.wide$ref.date), origin = \"1970-01-01\")\n",
    "  \n",
    "  return(list(daily.returns.data.long     = daily.returns.data.long,\n",
    "              daily.returns.data.wide     = daily.returns.data.wide,\n",
    "              cumulated.returns.data.long = cumulated.returns.data.long,\n",
    "              cumulated.returns.data.wide = cumulated.returns.data.wide))\n",
    "  \n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "PF.daily.return <- etlFinData(start.date = start.date,\n",
    "                             \n",
    "                              input.tickers.df = input.tickers.df)\n",
    "\n",
    "PF.daily.return.wide <- PF.daily.return$daily.returns.data.wide\n",
    "PF.daily.return.long <- PF.daily.return$daily.returns.data.long\n",
    "PF.daily.cumul.long  <- PF.daily.return$cumulated.returns.data.long \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5a345",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Shapiro-Wilk Test for Normality, \n",
    "# Null hypothesis: The data is normally distributed. If p> 0.05, normality can be assumed\n",
    "random.returns.example <- rnorm(5000)\n",
    "hist(random.returns.example)\n",
    "shapiro.test(random.returns.example)\n",
    "\n",
    "# HISTOGRAM LUKB\n",
    "  ggplot(PF.daily.return.wide, aes(x=LUKN.SW)) +\n",
    "  geom_histogram(colour=\"white\", fill=\"#7997FF\", alpha=0.6, position = 'identity', bins=25, aes(y=..density..)) +\n",
    "  scale_fill_manual(values=\"white\") + theme(legend.title = element_blank()) +\n",
    "  stat_function(fun = dnorm, args = list(mean = mean(PF.daily.return.wide$LUKN.SW), sd = sd(PF.daily.return.wide$LUKN.SW))) +\n",
    "  ggtitle(\"Histogram of Daily Returns\")  + ylab(\"count\")\n",
    "\n",
    " # QQ Plot - LUKB\n",
    " ggplot(PF.daily.return.wide) +\n",
    "  stat_qq(aes(sample = LUKN.SW),colour = \"#7997FF\") + stat_qq_line(aes(sample = LUKN.SW)) +\n",
    "  ggtitle(\"QQ Plot - LUKN.SW\") + xlab(\"theoretical\") + ylab(\"sample\")\n",
    "\n",
    "\n",
    "\n",
    "   # HISTOGRAM Bitcoin\n",
    "   ggplot(PF.daily.return.wide, aes(x=`Bitcoin (USD)`)) +\n",
    "    geom_histogram(colour=\"white\", fill=\"#F763E0\", alpha=0.6, position = 'identity', bins=25, aes(y=..density..)) +\n",
    "    scale_fill_manual(values=\"white\") + theme(legend.title = element_blank()) +\n",
    "    stat_function(fun = dnorm, args = list(mean = mean(PF.daily.return.wide$`Bitcoin (USD)`), sd = sd(PF.daily.return.wide$`Bitcoin (USD)`))) +\n",
    "    ggtitle(\"Histogram of Daily Returns\")  + ylab(\"count\")\n",
    "  \n",
    "  # QQ Plot - BITCOIN\n",
    "  ggplot(PF.daily.return.wide) +\n",
    "  stat_qq(aes(sample = `Bitcoin (USD)`),colour = \"#F763E0\") + stat_qq_line(aes(sample = `Bitcoin (USD)`)) +\n",
    "  ggtitle(\"QQ Plot - Bitcoin (USD)\") + xlab(\"theoretical\") + ylab(\"sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b48ce3",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cumulated return plot\n",
    "ggplot(PF.daily.cumul.long, aes(y=cumul.return, x=ref.date, color=name)) + geom_line(size=0.3)  \n",
    "\n",
    "# Vola plot\n",
    "ggplot(PF.daily.return.long, aes(y=daily.return, x=ref.date)) + geom_line(size=0.3)  + facet_grid(~ friendly.name)\n",
    "  \n",
    "PF.daily.return.long %>% group_by(friendly.name) %>% \n",
    "  summarise(min = min(daily.return)\n",
    "            ,max = max(daily.return)\n",
    "            ,mean = mean(daily.return)\n",
    "            ,sd = sd(daily.return)\n",
    "            ,n = n()\n",
    "            ,q05 = quantile(daily.return, .05)\n",
    "            ,q01 = quantile(daily.return, .01)\n",
    "            ,q95 = quantile(daily.return, .95)\n",
    "            ,q99 = quantile(daily.return, .99)\n",
    "            ,shapiro.normality.pvalue = as.numeric(shapiro.test(daily.return)[2])\n",
    "            ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf153a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "\n",
    "SMI <- PF.daily.return.wide %>%select(ref.date, SMI)\n",
    "Nestle <- PF.daily.return.wide %>%select(ref.date, Nestle)\n",
    "Roche <- PF.daily.return.wide %>%select(ref.date, Roche)\n",
    "Novartis <- PF.daily.return.wide %>%select(ref.date, Novartis)\n",
    "\n",
    "names(SMI)[names(SMI) == \"SMI\"] <- \"Return\"\n",
    "names(Nestle)[names(Nestle) == \"Nestle\"] <- \"Return\"\n",
    "names(Roche)[names(Roche) == \"Roche\"] <- \"Return\"\n",
    "names(Novartis)[names(Novartis) == \"Novartis\"] <- \"Return\"\n",
    "\n",
    "SMI$Rolling60 <- c(c(rep(NA, 59)), rollapply(SMI$Return, 60, sd)) * sqrt(250)\n",
    "SMI$Rolling120 <- c(c(rep(NA, 119)), rollapply(SMI$Return, 120, sd)) * sqrt(250)\n",
    "SMI$Rolling250 <- c(c(rep(NA, 249)), rollapply(SMI$Return, 250, sd)) * sqrt(250)\n",
    "SMI$Rolling500 <- c(c(rep(NA, 499)), rollapply(SMI$Return, 500, sd)) * sqrt(250)\n",
    "SMI$Rolling750 <- c(c(rep(NA, 749)), rollapply(SMI$Return, 750, sd)) * sqrt(250)\n",
    "SMI$Return <- NULL\n",
    "SMI <- reshape2::melt(SMI, id.vars=1, measure.vars = 2:5)\n",
    "ggplot(SMI, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"SMI\")\n",
    "\n",
    "Nestle$Rolling60 <- c(c(rep(NA, 59)), rollapply(Nestle$Return, 60, sd)) * sqrt(250)\n",
    "Nestle$Rolling120 <- c(c(rep(NA, 119)), rollapply(Nestle$Return, 120, sd)) * sqrt(250)\n",
    "Nestle$Rolling250 <- c(c(rep(NA, 249)), rollapply(Nestle$Return, 250, sd)) * sqrt(250)\n",
    "Nestle$Rolling500 <- c(c(rep(NA, 499)), rollapply(Nestle$Return, 500, sd)) * sqrt(250)\n",
    "Nestle$Rolling750 <- c(c(rep(NA, 749)), rollapply(Nestle$Return, 750, sd)) * sqrt(250)\n",
    "Nestle$Return <- NULL\n",
    "Nestle <- reshape2::melt(Nestle, id.vars=1, measure.vars = 2:5)\n",
    "ggplot(Nestle, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Nestle\")\n",
    "\n",
    "Roche$Rolling60 <- c(c(rep(NA, 59)), rollapply(Roche$Return, 60, sd)) * sqrt(250)\n",
    "Roche$Rolling120 <- c(c(rep(NA, 119)), rollapply(Roche$Return, 120, sd)) * sqrt(250)\n",
    "Roche$Rolling250 <- c(c(rep(NA, 249)), rollapply(Roche$Return, 250, sd)) * sqrt(250)\n",
    "Roche$Rolling500 <- c(c(rep(NA, 499)), rollapply(Roche$Return, 500, sd)) * sqrt(250)\n",
    "Roche$Rolling750 <- c(c(rep(NA, 749)), rollapply(Roche$Return, 750, sd)) * sqrt(250)\n",
    "Roche$Return <- NULL\n",
    "Roche <- reshape2::melt(Roche, id.vars=1, measure.vars = 2:5)\n",
    "ggplot(Roche, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Roche\")\n",
    "\n",
    "Novartis$Rolling60 <- c(c(rep(NA, 59)), rollapply(Novartis$Return, 60, sd)) * sqrt(250)\n",
    "Novartis$Rolling120 <- c(c(rep(NA, 119)), rollapply(Novartis$Return, 120, sd)) * sqrt(250)\n",
    "Novartis$Rolling250 <- c(c(rep(NA, 249)), rollapply(Novartis$Return, 250, sd)) * sqrt(250)\n",
    "Novartis$Rolling500 <- c(c(rep(NA, 499)), rollapply(Novartis$Return, 500, sd)) * sqrt(250)\n",
    "Novartis$Rolling750 <- c(c(rep(NA, 749)), rollapply(Novartis$Return, 750, sd)) * sqrt(250)\n",
    "Novartis$Return <- NULL\n",
    "Novartis <- reshape2::melt(Novartis, id.vars=1, measure.vars = 2:5)\n",
    "ggplot(Novartis, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Novartis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5caaca",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "\n",
    "SMI <- PF.daily.return.wide %>%select(ref.date, SMI)\n",
    "Nestle <- PF.daily.return.wide %>%select(ref.date, Nestle)\n",
    "Nestle$ref.date <-NULL\n",
    "SMI_Nestle = cbind(SMI, Nestle)\n",
    "SMI_Nestle$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(SMI_Nestle[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Nestle$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(SMI_Nestle[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Nestle$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(SMI_Nestle[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Nestle$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(SMI_Nestle[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Nestle$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(SMI_Nestle[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Nestle$Nestle <- NULL\n",
    "SMI_Nestle$SMI <- NULL                                \n",
    "SMI_Nestle <- reshape2::melt(SMI_Nestle, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(SMI_Nestle, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"SMI-Nestle\")\n",
    "                                                           \n",
    "SMI <- PF.daily.return.wide %>%select(ref.date, SMI)\n",
    "Novartis <- PF.daily.return.wide %>%select(ref.date, Novartis)\n",
    "Novartis$ref.date <-NULL\n",
    "SMI_Novartis = cbind(SMI, Novartis)\n",
    "SMI_Novartis$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(SMI_Novartis[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Novartis$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(SMI_Novartis[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Novartis$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(SMI_Novartis[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Novartis$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(SMI_Novartis[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Novartis$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(SMI_Novartis[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Novartis$Novartis <- NULL\n",
    "SMI_Novartis$SMI <- NULL                                \n",
    "SMI_Novartis <- reshape2::melt(SMI_Novartis, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(SMI_Novartis, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"SMI-Novartis\") \n",
    "                                                             \n",
    "SMI <- PF.daily.return.wide %>%select(ref.date, SMI)\n",
    "Roche <- PF.daily.return.wide %>%select(ref.date, Roche)\n",
    "Roche$ref.date <-NULL\n",
    "SMI_Roche = cbind(SMI, Roche)\n",
    "SMI_Roche$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(SMI_Roche[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Roche$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(SMI_Roche[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Roche$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(SMI_Roche[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Roche$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(SMI_Roche[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Roche$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(SMI_Roche[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "SMI_Roche$Roche <- NULL\n",
    "SMI_Roche$SMI <- NULL                                \n",
    "SMI_Roche <- reshape2::melt(SMI_Roche, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(SMI_Roche, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"SMI-Roche\")\n",
    "                                                          \n",
    "                                                          Novartis <- PF.daily.return.wide %>%select(ref.date, Novartis)\n",
    "Roche <- PF.daily.return.wide %>%select(ref.date, Roche)\n",
    "Roche$ref.date <-NULL\n",
    "Novartis_Roche = cbind(Novartis, Roche)\n",
    "Novartis_Roche$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(Novartis_Roche[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Roche$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(Novartis_Roche[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Roche$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(Novartis_Roche[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Roche$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(Novartis_Roche[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Roche$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(Novartis_Roche[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Roche$Roche <- NULL\n",
    "Novartis_Roche$Novartis <- NULL                                \n",
    "Novartis_Roche <- reshape2::melt(Novartis_Roche, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(Novartis_Roche, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Novartis-Roche\")\n",
    "                                                               \n",
    "Novartis <- PF.daily.return.wide %>%select(ref.date, Novartis)\n",
    "Nestle <- PF.daily.return.wide %>%select(ref.date, Nestle)\n",
    "Nestle$ref.date <-NULL\n",
    "Novartis_Nestle = cbind(Novartis, Nestle)\n",
    "Novartis_Nestle$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(Novartis_Nestle[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Nestle$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(Novartis_Nestle[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Nestle$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(Novartis_Nestle[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Nestle$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(Novartis_Nestle[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Nestle$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(Novartis_Nestle[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Novartis_Nestle$Nestle <- NULL\n",
    "Novartis_Nestle$Novartis <- NULL                                \n",
    "Novartis_Nestle <- reshape2::melt(Novartis_Nestle, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(Novartis_Nestle, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Novartis-Nestle\") \n",
    "                                                                \n",
    "Roche <- PF.daily.return.wide %>%select(ref.date, Roche)\n",
    "Nestle <- PF.daily.return.wide %>%select(ref.date, Nestle)\n",
    "Nestle$ref.date <-NULL\n",
    "Roche_Nestle = cbind(Roche, Nestle)\n",
    "Roche_Nestle$RollingCorr60 <- c( c(rep(NA, 59)), rollapply(Roche_Nestle[-1], 60, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Roche_Nestle$RollingCorr120 <- c( c(rep(NA, 119)), rollapply(Roche_Nestle[-1], 120, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Roche_Nestle$RollingCorr250 <- c( c(rep(NA, 249)), rollapply(Roche_Nestle[-1], 250, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Roche_Nestle$RollingCorr500 <- c( c(rep(NA, 499)), rollapply(Roche_Nestle[-1], 500, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Roche_Nestle$RollingCorr750 <- c( c(rep(NA, 749)), rollapply(Roche_Nestle[-1], 750, function(x) cor(x[,1],x[,2]), by.column=FALSE))\n",
    "Roche_Nestle$Nestle <- NULL\n",
    "Roche_Nestle$Roche <- NULL                                \n",
    "Roche_Nestle <- reshape2::melt(Roche_Nestle, id.vars=1, measure.vars = 2:5)                                                         \n",
    "ggplot(Roche_Nestle, aes(y=value, x=ref.date, color=variable)) + geom_line(size=0.3) + ggtitle(\"Roche-Nestle\")                                                                \n",
    "                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6edad",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "\n",
    "## Covariance\n",
    "\n",
    "### Sample Covariance\n",
    "The sample covariance is defined as follows\n",
    "\\begin{equation}\n",
    "s_{xy}=\\frac{1}{n-1}\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y}))\n",
    "\\end{equation}\n",
    "\n",
    "### Correlation\n",
    "\n",
    "\n",
    "### Covariance of Portfolio (Covariance Matrix)\n",
    "The portfolio's covariance is defined as follows\n",
    "\n",
    "\\begin{multline}\n",
    "\\sigma^{2}_p=Var(R_p) \n",
    "= Var\\left ( \\sum_{i=1}^{k}w_i*R_i(t) \\right ) \n",
    "=Cov\\left ( \\sum_{i=1}^{k}w_i*R_i(t),\\sum_{j=1}^{k}w_j*R_j(t) \\right ) \\\\ \n",
    "=\\sum_{i=1}^{k}\\sum_{j=1}^{k}w_i w_jCov(R_i(t),R_j(t)) \n",
    "=w^T\\Sigma w\n",
    "\\end{multline}\n",
    "\n",
    "where $\\Sigma$ is the $k \\times k$ covariance matrix with entries \\(\\sigma\\) = Cov\\( Ri,Rj \\).\n",
    "\n",
    "\n",
    "#### Covariance Matrix Decomposition\n",
    "A covariance matrix can be decomposed into a volatility vector \\(\\sigma\\) and a correlation matrix $R$:\n",
    "\n",
    "We first create a diagonal standard deviation matrix $S$, which looks like this:\n",
    "\n",
    "\n",
    "\n",
    "$S=\\begin{pmatrix}\n",
    "\\sigma _{1} &0  &... &0 \\\\ \n",
    " 0& \\sigma _{2} &... &0 \\\\ \n",
    " \\vdots &  &  \\ddots &0 \\\\ \n",
    "0& ...\\ & ...\\ & \\sigma _{n}\n",
    "\\end{pmatrix}$\n",
    "\n",
    " \n",
    "and the correlation matrix $R$:\n",
    "\n",
    "\n",
    "$R=\\begin{pmatrix}\n",
    "1 & \\rho _{12} &...  &\\rho _{1n}\\\\ \n",
    " \\rho _{21} &1& ... &\\rho _{2n} \\\\ \n",
    " \\vdots &  &  \\ddots & \\\\ \n",
    "\\rho _{n1}& ...\\ & ...\\ & 1\n",
    "\\end{pmatrix}$\n",
    "\n",
    "\n",
    "So our covariance matrix $\\Sigma$ is generated by first multiplying the correlation matrix with the diagonal standard deviation matrix and then again multiplying by the transposed diagonal volatility matrix (as however $S$ is a diagonal matrix, it does not matter whether we take the transposed matrix or not, so $S=S^{^{T}}$). \n",
    "\n",
    "$\\Sigma =SRS$\n",
    "\n",
    "This decomposition can be helpful if we want to control the specific inputs, i.e. the correlation or the volatilites. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba90d9d",
   "metadata": {},
   "source": [
    "### Covariance: Code Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcd74b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"ggcorrplot\")\n",
    "library(ggcorrplot)\n",
    "\n",
    "PF.daily.return.data <- etlFinData(start.date=as.Date(\"2021-01-01\"),\n",
    "                                input.tickers.df = data.frame(ticker=c(\"^IXIC\",\"AAPL\",\"FB\",\"INTC\",\"MSFT\",\"ABNB\",\"ADBE\",\"AMZN\",\"EA\"),\n",
    "                                                              friendly.name=c(\"Nasdaq\",\"Apple\",\"Facebook\",\"Intel\",\"Microsoft\",\"AirBnB\",\"Adobe\",\"Amazon\",\"EA\"))) \n",
    "  \n",
    "  PF.daily.return.data.wide <- PF.daily.return.data$daily.returns.data.wide\n",
    "  \n",
    "  PF.correl.matrix <- cor(PF.daily.return.data.wide[,2:ncol(PF.daily.return.data.wide)])\n",
    "  library(ggcorrplot)\n",
    "  \n",
    "  ggcorrplot(\n",
    "    PF.correl.matrix,\n",
    "    hc.order = TRUE,\n",
    "    #type = \"lower\",\n",
    "    outline.color = \"white\",\n",
    "    ggtheme = ggplot2::theme_gray,\n",
    "    colors = c(\"#6D9EC1\", \"white\", \"#E46726\"),\n",
    "    lab = TRUE\n",
    "  )\n",
    "\n",
    "# Note that the slope of a linear regression is not the same as the correlation coefficient (!)\n",
    "  ggplot(PF.daily.return.data.wide, aes(x=Nasdaq, y=Microsoft)) + geom_point() +\n",
    "    geom_smooth(method=lm, se=FALSE)\n",
    " \n",
    "# Correlation example Microsoft, Nasdaq\n",
    "  correl.manual = cov(PF.daily.return.data.wide$Microsoft, PF.daily.return.data.wide$Nasdaq) / (sd(PF.daily.return.data.wide$Microsoft)*sd(PF.daily.return.data.wide$Nasdaq))\n",
    "  print(correl.manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128836af",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Value at Risk ##\n",
    "As defined by Wilmott (2007) <em>Value at Risk (VaR)</em> \n",
    "\"is an estimate, with a given degree of confidence, of how much on can lose from one's portfolio over a given time horizon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0423789",
   "metadata": {},
   "source": [
    "### Parametrical (delta-normal) VaR ###\n",
    "\n",
    "#### Parametrical Value at Risk for single Assets ####\n",
    "The parametrical Value at Risk (VaR) is also called analytical VaR, it is based on a mean-variance or delta-normal approach. \n",
    "It basically only requires an estimation of the mean and the volatility of the returns, which are assumed to be normally distributed.\n",
    "\n",
    "$\\Delta$ represents the quantity of the asset hold with price $S$ and volatility $\\sigma$.\n",
    "\n",
    "\\begin{equation}\n",
    "VaR^{param}=-\\sigma \\Delta S(\\delta t)^{1/2}\\alpha (1-c)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $\\alpha\\left ( \\cdot  \\right )$ is the inverse cumulative distribution function for the standardized Normal distribution. \n",
    "$(\\delta t)$ is the time horizon (usually one to five days) and $c$ is the degree of confidence (e.g. 0.95 or 0.99). \n",
    "The mean of the distribution is assumed to be zero (which is reasonable for short time periods, such as in the VaR, which are usually ranging from one to five days).\n",
    "\n",
    "If we assume that the returns are not autocorrelated, we can simply scale the volatility by $\\sqrt{t}$, if we e.g. have a daily volatility $\\sigma$ of 1.5\\% and a confidence level of 99\\% and a holding period of 5 days we get:\n",
    "\n",
    "$VaR_{5d @0.99}^{param}=-0.015 \\times \\Delta S \\times \\sqrt{5} \\times 2.33$\n",
    "\n",
    "#### Parametrical Value at Risk for Portfolios #### \n",
    "The parametric VaR of a portfolio can be calculated in the following way:\n",
    "\n",
    "\\begin{equation}\n",
    "VaR_{PF}^{param}=\\upsilon \\Pi  \\upsilon ^{T}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\upsilon$ is the vector of the single Assets VaR figures and $\\Pi $ is the correlation matrix of the assets' returns.\n",
    "\n",
    "### Historical (Non-parametrical) Value at Risk ###\n",
    "The nonparametric or historical VaR is simply derived from historical data. This has the advantage that we do not estimate any return distribution functions or worry about volatilities.  \n",
    "\n",
    "\\begin{equation}\n",
    "VaR_{1-\\alpha}^{hist}=R_\\alpha\n",
    "\\end{equation}\n",
    "\n",
    "$VaR_{1-\\alpha}$ is the VaR at a confidence level of $1-\\alpha$ or in other words the $\\alpha$ th's worst return is our VaR. If we have 100 daily returns and we want to know the 95\\% VaR, we simply look at the 5th worst daily return, which corresponds to the historical VaR at a 95\\% confidence level.\n",
    "\n",
    "### Conditional Value at Risk or Expected Shortfall ###\n",
    "Conditional Value-at-Risk or also commonly known as Expected Shortfall, is the amount $\\alpha$ which is the conditional expectation of losses above a specified probability level $\\beta$. The $\\beta$-VaR of a portfolio is the lowest amount $\\alpha$ such that, the loss will not be above $\\alpha$.  The $\\beta$-CVaR\n",
    "is the conditional expectation of losses exceeding $\\alpha$. So the CVaR is the mean of all returns that are beyond (or \"worse\" than) VaR. Therefore CVaR is always more severe than VaR, which shows also the focus on the more extreme tail risks that are not captured by VaR (as with VaR we do not know how much worse it can go once we have breached VaR). \n",
    "\n",
    "Mathematically CVaR can be defined as\n",
    "\n",
    "\\begin{equation}\n",
    "CVaR_{\\alpha }(X)=\\frac{1}{\\alpha }\\int_{0}^{\\alpha }VaR_{\\beta }(X)d\\beta \n",
    "\\end{equation}\n",
    "\n",
    "or alternatively \n",
    "\n",
    "\\begin{equation}\n",
    "CVaR_{\\alpha }(X)=E\\left [ X|X\\geq VaR_{\\alpha }(X) \\right ]\n",
    "\\end{equation}\n",
    "\n",
    "As with VaR, CVaR can be parametrical or non-parametrical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c02ca1",
   "metadata": {},
   "source": [
    "### Value at Risk: Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe785c7c",
   "metadata": {},
   "source": [
    "#### Value at Risk: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd861ad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# VaR Functions\n",
    "\n",
    "#' @param daily.volatility The applied volatility for the shift\n",
    "#' @param VaR.confidence Confidence level of the Value at Risk (VaR) shift\n",
    "#' @param VaR.period.days Holding period in days for the VaR shift\n",
    "#' @return a shifted price according to volatility, VaR confidence level and VaR period\n",
    "#' @name VaRparamSingle\n",
    "#' @examples\n",
    "#' VaR(price=100, position=1, daily.volatility=0.01, VaR.confidence=0.99, VaR.period.days=5)\n",
    "#' @export\n",
    "VaRparamSingle <- function(daily.volatility, VaR.confidence=0.99, VaR.period.days=5) {\n",
    "  param.var.single = -daily.volatility*qnorm(VaR.confidence)*sqrt(VaR.period.days)\n",
    "  return(param.var.single)\n",
    "}\n",
    "\n",
    "\n",
    "#' @title VaRparamPortfolio\n",
    "#' @description This function returns the Value at Risk of a Portfolio\n",
    "#' @param vector with individual.var\n",
    "#' @param correlation.matrix\n",
    "#' @return a Portfolio VaR\n",
    "#' @name VaRparamPortfolio\n",
    "#' @export\n",
    "VaRparamPortfolio <- function(individual.var.vector, correlation.matrix) {\n",
    "\n",
    "  portfolio.var <- sqrt(individual.var.vector  %*% correlation.matrix  %*% individual.var.vector)\n",
    "  return(portfolio.var)\n",
    "}\n",
    "\n",
    "\n",
    "#' @param VaR.confidence Confidence level of the Value at Risk (VaR) shift\n",
    "#' @param historical.return.ts - Historical returns timeseries of single stock\n",
    "#' @param price Original price (pre-shift) per unit\n",
    "#' @param position size of the position\n",
    "\n",
    "VaRHistSimSingle <- function(historical.return.ts, VaR.confidence) {\n",
    "\n",
    "hs.var.single <- as.numeric(quantile(historical.return.ts,1-VaR.confidence))                       \n",
    "return(hs.var.single)\n",
    "}    \n",
    "\n",
    "#' @param daily.returns.ts - Historical returns timeseries of single stock  \n",
    "#' @param VaR.confidence Confidence level of the Value at Risk (VaR) shift\n",
    "#' @param lambda - time decay factor\n",
    "  VaRHistSimWeightSingle <- function(daily.returns.ts, lambda, VaR.confidence) {\n",
    "    \n",
    "    K = length(daily.returns.ts)\n",
    "    hist.return.data <- data.frame(return=daily.returns.ts, days.ago.n=c(1:K))\n",
    "    hist.return.data$time.weight <- (1-lambda)*lambda^(hist.return.data$days.ago.n-1)/(1-lambda^K)\n",
    "    hist.return.data2 <- hist.return.data[order(hist.return.data$return),]\n",
    "    hist.return.data2$weight.cumul <- cumsum(hist.return.data2$time.weight)\n",
    "    var.hist.time.weighted <- approx(x=hist.return.data2$weight.cumul, y=hist.return.data2$return, xout=1-VaR.confidence)$y\n",
    "    return(var.hist.time.weighted)\n",
    "  }   \n",
    "   \n",
    "\n",
    "\n",
    "EWMAvolaEstim <- function(daily.returns.ts,lambda=0.94,time.period=100) {\n",
    "    \n",
    "    ewma.vector <- (1-lambda)*lambda^(c(1:time.period)-1)/(1-lambda^time.period)\n",
    "    estimation.vola.yesterday <- sqrt(sum(daily.returns.ts[2:(time.period+1)]^2*ewma.vector))\n",
    "    estimation.return2        <- daily.returns.ts[2]^2\n",
    "    \n",
    "    estimation.vola.today <- sqrt(lambda*estimation.vola.yesterday^2 + (1-lambda)*estimation.return2)\n",
    "    return(estimation.vola.today)\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "# Conditional VaR / Expected Shortfall Using Historical Returns\n",
    "# description calculates the historical Conditional VaR / Expected Shortfall of a portfolio or an asset\n",
    "# param daily.returns Daily historical returns of a portfolio or single asset\n",
    "# param alpha.cvar Alpha of the CVaR, this is the confidence level from which on the average of the tail risk is being calculated\n",
    "# return cvar CVaR of the specific portfolio or asset with the set alpha\n",
    "histCVaRcalc <- function(asset.weights=1, daily.returns.data.wide, alpha.cvar) {\n",
    "  i.num = ceiling(alpha.cvar * nrow(daily.returns.data.wide))\n",
    "  portfolio.returns <- as.matrix(daily.returns.data.wide[,2:length(daily.returns.data.wide)]) %*% c(asset.weights)\n",
    "  portfolio.returns <- sort(portfolio.returns)\n",
    "  cvar = mean(portfolio.returns[1:i.num])\n",
    "  return(cvar)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8f337",
   "metadata": {},
   "source": [
    "#### Code Examples - Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf29c0d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# VaR (1 title) - LuKB\n",
    "\n",
    "# 1d VaR, 99% confidence\n",
    "\n",
    "historical.return.ts <- PF.daily.return.wide$LUKN.SW\n",
    "VaR.confidence  = 0.99 # confidence level\n",
    "VaR.period.days = 1    # holding period\n",
    "time.period     = 100  # num historical days \n",
    "lambda          = 0.94 # time decay factor\n",
    "\n",
    "\n",
    "# Example - Parametric VaR \n",
    "param.var.single <- VaRparamSingle(\n",
    "                                daily.volatility=sd(historical.return.ts[1:time.period]),\n",
    "                                VaR.confidence=VaR.confidence,\n",
    "                                VaR.period.days=VaR.period.days)\n",
    "\n",
    "# Example - Hist Single VaR \n",
    "hs.var.single <- VaRHistSimSingle(historical.return.ts[1:time.period], VaR.confidence)\n",
    "\n",
    "# Example - Hist Weight Single VaR \n",
    "hs.weight.var.single <- VaRHistSimWeightSingle(historical.return.ts[1:time.period], lambda, VaR.confidence)\n",
    "\n",
    "\n",
    "# Example - EWMA\n",
    "ewma.vola <- EWMAvolaEstim(historical.return.ts,lambda,time.period)\n",
    "ewma.var <- -ewma.vola*qnorm(VaR.confidence)\n",
    "\n",
    "\n",
    "result.table <- data.frame(var.model=c(\"parametric\",\"historical simulation\", \"HS time weighted\", \"EWMA\"),\n",
    "                           var.result=c(param.var.single,hs.var.single,hs.weight.var.single, ewma.var))\n",
    "\n",
    "\n",
    "print(result.table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9741af",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Auto Correlation Function plot \n",
    "plot(acf(historical.return.ts^2))\n",
    "\n",
    "\n",
    "\n",
    "### EWMA plot\n",
    "lambda <- 0.95\n",
    "K <- 100\n",
    "ewma <- (1-lambda)*lambda^(c(1:K)-1)/(1-lambda^K)\n",
    "plot(ewma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d193f52",
   "metadata": {},
   "source": [
    "#### Code Examples - VaR Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071775ff",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Value at Risk Backtesting\n",
    "  \n",
    "  return.lukb <- historical.return.ts\n",
    "  length.data <- length(return.lukb)\n",
    "  daily.vola.lukb <- vector(length=length(PF.daily.return.wide$LUKN.SW)-29)\n",
    "   for (i in 30:length.data) {\n",
    "    daily.vola.lukb[i] <- (sd(return.lukb[i-29:i]))\n",
    "   }\n",
    "  \n",
    "  backtesting.data <- data.frame(daily.return=return.lukb[30:length.data],\n",
    "                         daily.vola.rolling=daily.vola.lukb[30:length.data])\n",
    "  \n",
    "  backtesting.data$var95.up <- backtesting.data$daily.vola.rolling*qnorm(0.95)\n",
    "  backtesting.data$var99.up <- backtesting.data$daily.vola.rolling*qnorm(0.99)\n",
    "  backtesting.data$var95.down <- backtesting.data$daily.vola.rolling*-qnorm(0.95)\n",
    "  backtesting.data$var99.down <- backtesting.data$daily.vola.rolling*-qnorm(0.99)\n",
    "  backtesting.data$date <- PF.daily.return.wide$ref.date[30:nrow(PF.daily.return.wide)]\n",
    "  \n",
    "  ggplot(data=backtesting.data, aes(x=date, y=daily.return)) + geom_point(size=1,color=\"black\") + geom_line(size=0.3, color=\"#7997FF\", linetype=1) +\n",
    "  geom_ribbon(aes(ymin=var95.down,ymax=var95.up), linetype=2, alpha=0.3, colour=\"red\") +\n",
    "  geom_ribbon(aes(ymin=var99.down,ymax=var99.up), linetype=2, alpha=0.2, colour=\"darkred\") +\n",
    "  ggtitle(\"VaR Backtesting - LUKN.SW (95% vs 99% Confidence)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6531a1e",
   "metadata": {},
   "source": [
    "#### Code Examples - Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86119d19",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "return.dat.multiple <- PF.daily.return.data.wide[,2:ncol(PF.daily.return.data.wide)]\n",
    "head(return.dat.multiple)\n",
    "plot(princomp(return.dat.multiple))\n",
    "  \n",
    "  pca.result <- princomp(return.dat.multiple)\n",
    "  summary(pca.result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734632a",
   "metadata": {},
   "source": [
    "## Option Valuation & Greeks\n",
    "### Black Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dadeb6f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Black Scholes\n",
    "\n",
    "BlackScholesValuation <- function(S, K, T, vola, rf) {\n",
    "  \n",
    "  d1 = (log(S/K) + (rf+0.5*vola^2) * T) / (vola*sqrt(T))\n",
    "  d2 = d1 - vola*sqrt(T)\n",
    "  \n",
    "  call.value = S*pnorm(d1) - K*exp(-rf*T)*pnorm(d2)\n",
    "  put.value  = K*exp(-rf*T)*pnorm(-d2) - S*pnorm(-d1) \n",
    "    \n",
    "  call.delta = pnorm(d1)\n",
    "  put.delta  = call.delta-1\n",
    "    \n",
    "  results <- list(call.value=call.value, put.value=put.value, call.delta= call.delta, put.delta = put.delta )\n",
    "  return(results)\n",
    "}\n",
    "\n",
    "\n",
    "### Implied Vola helper\n",
    "volaOptimizer <- function(vola, option.price, S, K, rf, T, option.type) {\n",
    "  if(option.type==\"call\") {abs(option.price - BlackScholesValuation(S, K, T, vola, rf)$call.value)} else {\n",
    "    abs(option.price - BlackScholesValuation(S, K, T, vola, rf)$put.value) }\n",
    "}\n",
    "\n",
    "## find Implied Vola\n",
    "findImpliedVola <- function(option.price, S, K, rf, T, option.type) {\n",
    "implied.vola <- optimize(volaOptimizer, interval = c(0, 2), option.price = option.price, S = S, K = K, rf = rf, T = T, option.type = \"call\")$minimum\n",
    "return(implied.vola)\n",
    "}\n",
    "\n",
    "# Monte Carlo One Step Simulation \n",
    "MCOneStepSimulation <- function(S, dt, vola, rf, num.simulations, method) {\n",
    "  \n",
    "  if(!(method %in% c(\"Euler\",\"Ito\"))) {stop(\"method must be Euler or Ito\")} \n",
    "  \n",
    "  set.seed(20180425)\n",
    "  \n",
    "  if(method==\"Euler\") {\n",
    "    ST = S + S*rf*dt + vola*S*sqrt(dt)*rnorm(num.simulations)\n",
    "  }\n",
    "  \n",
    "  if(method==\"Ito\") {\n",
    "    ST = S*exp((rf-0.5*vola^2)*dt+sqrt(dt)*vola*rnorm(num.simulations)) \n",
    "  }    \n",
    "  return(ST)\n",
    "}\n",
    "\n",
    "EulerPathSimulator <- function(num.steps=252, num.simulations, num.discrete.steps=12, S, vola, rf) {\n",
    "  \n",
    "  \n",
    "  sim.list <- vector(\"list\", num.simulations)  \n",
    "  \n",
    "  for(i in 1:num.simulations) {\n",
    "    single.simulation.df    <- data.frame(id.simulation=i,day=c(1:num.steps), S.cont=NA, S.discrete=NA)\n",
    "    single.simulation.df$S.cont                <- (1+cumsum(c(0,log(1+rf)/num.steps + vola/sqrt(num.steps)*rnorm(num.steps-1))))*S\n",
    "    single.simulation.df$S.discrete            <- ifelse(single.simulation.df$day %% num.discrete.steps ==0, single.simulation.df$S.cont, NA)\n",
    "    single.simulation.df$S.discrete[1]         <- S\n",
    "    single.simulation.df$S.discrete            <- na.approx(single.simulation.df$S.discrete, method=\"constant\")\n",
    "    single.simulation.df$S.cont.mean.arith     <- cumsum(single.simulation.df$S.cont)/single.simulation.df$day\n",
    "    single.simulation.df$S.discrete.mean.arith <- cumsum(single.simulation.df$S.discrete)/single.simulation.df$day\n",
    "    single.simulation.df$S.cont.mean.geom      <- exp(cumsum(log(single.simulation.df$S.cont)) / single.simulation.df$day)\n",
    "    single.simulation.df$S.discrete.mean.geom  <- exp(cumsum(log(single.simulation.df$S.discrete)) / single.simulation.df$day)\n",
    "    \n",
    "    sim.list[[i]] <- single.simulation.df\n",
    "    }\n",
    "  \n",
    "  sim.df <- plyr::rbind.fill(sim.list)\n",
    "  \n",
    "  \n",
    "return(data.frame(sim.df))\n",
    "}\n",
    "\n",
    "\n",
    "# Monte Carlo European Option Valuation\n",
    "MCEuropeanOptionValuation <- function(S, K ,dt, T, vola, rf, num.simulations, method) {\n",
    "  \n",
    "  simulated.ST <-  MCOneStepSimulation(S=S, dt=dt, vola=vola, rf=rf, num.simulations = num.simulations, method = method)\n",
    "  call.value   <- exp(-rf)*mean(pmax(simulated.ST-K,0))\n",
    "  put.value    <- exp(-rf)*mean(pmax(K-(simulated.ST),0))\n",
    "  result.df    <- data.frame(call.value=call.value, put.value=put.value,num.simulations=num.simulations)\n",
    "  return(result.df)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0ac93",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#install.packages(\"zoo\")\n",
    "library(zoo)\n",
    "library(ggplot2)\n",
    "\n",
    "\n",
    "####################\n",
    "# SET PARAMETERS\n",
    "S    = 100 # stock price\n",
    "K    = 100 # strike price\n",
    "T    = 1 # time to expiry\n",
    "vola = 0.2 # sigma\n",
    "rf   = 0.05 # risk free rate\n",
    "dt   = 1\n",
    "method = \"Euler\"\n",
    "\n",
    "# BLACK SCHOLES VALUATION\n",
    "BS.option.value <- BlackScholesValuation(S=S, K=K, T=T, vola=vola, rf=rf)\n",
    "print(BS.option.value)\n",
    "\n",
    "\n",
    "# Delta \n",
    "S.shift = seq(0.5*S,1.5*S, by=0.5)\n",
    "delta.call = BlackScholesValuation(S=S.shift , K=K, T=T, vola=vola, rf=rf)$call.delta\n",
    "delta.put = BlackScholesValuation(S=S.shift , K=K, T=T, vola=vola, rf=rf)$put.delta\n",
    "\n",
    "result.delta <- data.frame(S.shift = S.shift, delta.call = delta.call, delta.put = delta.put)\n",
    "\n",
    "ggplot(result.delta, aes(x=S.shift)) + \n",
    "  geom_line(aes(y = delta.call), color = \"darkred\") + \n",
    "geom_line(aes(y = delta.put), color = \"blue\") \n",
    "\n",
    "\n",
    "# Implied Vola\n",
    "option.price = 10\n",
    "implied.vola <- findImpliedVola(option.price, S, K, rf, T, option.type=\"call\")\n",
    "print(paste(\"Implied Vola with Option price:\",option.price,\"CHF\",\"is:\",round(implied.vola,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b204a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MONTE CARLO EUROPEAN - EULER\n",
    "result.df.euler <- NULL ; result.sim <- NULL\n",
    "\n",
    "for(i in 1:10^4) {\n",
    "  result.sim <- MCEuropeanOptionValuation(S=S, K=K, dt=1, T=T, vola=vola, rf=rf, num.simulations=i, method=\"Euler\")\n",
    "  result.df.euler <- rbind(result.df.euler, result.sim)\n",
    "}\n",
    "result.df.euler$call.error <- result.df.euler$call.value - BS.option.value$call.value\n",
    "result.df.euler$put.error <- result.df.euler$put.value - BS.option.value$put.value\n",
    "result.df.euler[10000,]\n",
    "\n",
    "plot(result.df.euler$call.error, type=\"l\", col=\"red\", main=\"Monte Carlo (Euler) vs Black Scholes - 10k sim\", xlab=\"Number of Simulations\", ylab=\"Valuation Error\")\n",
    "abline( h = 0, col = \"gray40\")\n",
    "\n",
    "plot(result.df.euler$call.error[1:100], type=\"l\", col=\"red\", main=\"Monte Carlo (Euler) vs Black Scholes - 100 sim\", xlab=\"Number of Simulations\", ylab=\"Valuation Error\")\n",
    "abline( h = 0, col = \"gray40\")\n",
    "\n",
    "#######################################\n",
    "\n",
    "# MONTE CARLO EUROPEAN - ITO\n",
    "result.df.ito <- NULL ; result.sim <- NULL\n",
    "for(i in 1:10^4) {\n",
    "  result.sim <- MCEuropeanOptionValuation(S=S, K=K, dt=1, T=T, vola=vola, rf=rf, num.simulations=i, method=\"Ito\")\n",
    "  result.df.ito <- rbind(result.df.ito, result.sim)\n",
    "}\n",
    "result.df.ito$call.error <- result.df.ito$call.value - BS.option.value$call.value\n",
    "result.df.ito$put.error  <- result.df.ito$put.value - BS.option.value$put.value\n",
    "result.df.ito[10000,]\n",
    "\n",
    "plot(result.df.ito$call.error, type=\"l\", col=\"red\", main=\"Monte Carlo (Ito) vs Black Scholes - 10k sim\", xlab=\"Number of Simulations\", ylab=\"Valuation Error\")\n",
    "abline( h = 0, col = \"gray40\")\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "single.simulation.df <- EulerPathSimulator(num.steps=252, num.simulations=1, num.discrete.steps=18, S=S, vola=vola, rf=rf)\n",
    "\n",
    "plot(single.simulation.df$S.cont, type=\"l\",\n",
    "     main=\"Simulated Price Path\",xlab=\"Days\",ylab=\"Price\", col=\"blue\")\n",
    "lines(x=single.simulation.df$S.discrete,col=\"red\",type=\"l\")\n",
    "legend(x=\"topleft\", legend=c(\"Continuous\", \"Discrete\"),\n",
    "       col=c(\"blue\", \"red\"), lty=1:1, cex=0.8, box.lty=1)\n",
    "\n",
    "plot(single.simulation.df$S.cont, type=\"l\",\n",
    "     main=\"Simulated Price Path\",xlab=\"Days\",ylab=\"Price\", col=\"blue\")\n",
    "lines(x=single.simulation.df$S.cont.mean.arith,col=\"red\",type=\"l\")\n",
    "lines(x=single.simulation.df$S.cont.mean.geom,col=\"green\",type=\"l\")\n",
    "legend(x=\"topleft\", legend=c(\"Geometric mean\", \"Arithmetic mean\"),\n",
    "       col=c(\"green\", \"red\"), lty=1:1, cex=0.8, box.lty=1)\n",
    "\n",
    "#######################################\n",
    "\n",
    "# ASIAN OPTION VALUATION\n",
    "\n",
    "num.simulations =10^4\n",
    "num.steps = 252\n",
    "sim.df <- EulerPathSimulator(num.steps=num.steps, num.simulations=num.simulations, num.discrete.steps=18, S=S, vola=vola, rf=rf)\n",
    "\n",
    "summary.sim.df <- sim.df[sim.df$day==num.steps,]\n",
    "\n",
    "# fixed strike\n",
    "\n",
    "summary.sim.df$asian.call.fixed.arith.cont <- exp(-rf*T)*pmax(summary.sim.df$S.cont.mean.arith-K,0)\n",
    "summary.sim.df$asian.call.fixed.geom.cont  <- exp(-rf*T)*pmax(summary.sim.df$S.cont.mean.geom-K,0)\n",
    "summary.sim.df$asian.put.fixed.arith.cont  <- exp(-rf*T)*pmax(K-summary.sim.df$S.cont.mean.arith,0)\n",
    "summary.sim.df$asian.put.fixed.geom.cont   <- exp(-rf*T)*pmax(K-summary.sim.df$S.cont.mean.geom,0)\n",
    "\n",
    "summary.sim.df$asian.call.fixed.arith.disc <- exp(-rf*T)*pmax(summary.sim.df$S.discrete.mean.arith-K,0)\n",
    "summary.sim.df$asian.call.fixed.geom.disc  <- exp(-rf*T)*pmax(summary.sim.df$S.discrete.mean.geom-K,0)\n",
    "summary.sim.df$asian.put.fixed.arith.disc  <- exp(-rf*T)*pmax(K-summary.sim.df$S.discrete.mean.arith,0)\n",
    "summary.sim.df$asian.put.fixed.geom.disc   <- exp(-rf*T)*pmax(K-summary.sim.df$S.discrete.mean.geom,0)\n",
    "\n",
    "\n",
    "\n",
    "# floating strike\n",
    "\n",
    "summary.sim.df$asian.call.floating.arith.cont <- exp(-rf*T)*pmax(summary.sim.df$S.cont-summary.sim.df$S.cont.mean.arith,0)\n",
    "summary.sim.df$asian.call.floating.geom.cont  <- exp(-rf*T)*pmax(summary.sim.df$S.cont-summary.sim.df$S.cont.mean.geom,0)\n",
    "summary.sim.df$asian.put.floating.arith.cont  <- exp(-rf*T)*pmax(summary.sim.df$S.cont.mean.arith-summary.sim.df$S.cont,0)\n",
    "summary.sim.df$asian.put.floating.geom.cont   <- exp(-rf*T)*pmax(summary.sim.df$S.cont.mean.geom-summary.sim.df$S.cont,0)\n",
    "\n",
    "summary.sim.df$asian.call.floating.arith.disc <- exp(-rf*T)*pmax(summary.sim.df$S.discrete-summary.sim.df$S.discrete.mean.arith,0)\n",
    "summary.sim.df$asian.call.floating.geom.disc  <- exp(-rf*T)*pmax(summary.sim.df$S.discrete-summary.sim.df$S.discrete.mean.geom,0)\n",
    "summary.sim.df$asian.put.floating.arith.disc  <- exp(-rf*T)*pmax(summary.sim.df$S.discrete.mean.arith-summary.sim.df$S.discrete,0)\n",
    "summary.sim.df$asian.put.floating.geom.disc   <- exp(-rf*T)*pmax(summary.sim.df$S.discrete.mean.geom-summary.sim.df$S.discrete,0)\n",
    "\n",
    "\n",
    "asian.option.fixed.valuation.summary <- data.frame(num.simulations = max(summary.sim.df$id.simulation),\n",
    "                                     asian.call.fixed.arith.cont = mean(summary.sim.df$asian.call.fixed.arith.cont),\n",
    "                                     asian.call.fixed.geom.cont  = mean(summary.sim.df$asian.call.fixed.geom.cont),\n",
    "                                     asian.put.fixed.arith.cont  = mean(summary.sim.df$asian.put.fixed.arith.cont),\n",
    "                                     asian.put.fixed.geom.cont   = mean(summary.sim.df$asian.put.fixed.geom.cont),\n",
    "                                     asian.call.fixed.arith.disc = mean(summary.sim.df$asian.call.fixed.arith.disc),\n",
    "                                     asian.call.fixed.geom.disc  = mean(summary.sim.df$asian.call.fixed.geom.disc),\n",
    "                                     asian.put.fixed.arith.disc  = mean(summary.sim.df$asian.put.fixed.arith.disc),\n",
    "                                     asian.put.fixed.geom.disc   = mean(summary.sim.df$asian.put.fixed.geom.disc)\n",
    "                                      )\n",
    "\n",
    "\n",
    "\n",
    "asian.option.floating.valuation.summary <- data.frame(num.simulations = max(summary.sim.df$id.simulation),\n",
    "                                                      asian.call.floating.arith.cont = mean(summary.sim.df$asian.call.floating.arith.cont),\n",
    "                                                      asian.call.floating.geom.cont  = mean(summary.sim.df$asian.call.floating.geom.cont),\n",
    "                                                      asian.put.floating.arith.cont  = mean(summary.sim.df$asian.put.floating.arith.cont),\n",
    "                                                      asian.put.floating.geom.cont   = mean(summary.sim.df$asian.put.floating.geom.cont),\n",
    "                                                      asian.call.floating.arith.disc = mean(summary.sim.df$asian.call.floating.arith.disc),\n",
    "                                                      asian.call.floating.geom.disc  = mean(summary.sim.df$asian.call.floating.geom.disc),\n",
    "                                                      asian.put.floating.arith.disc  = mean(summary.sim.df$asian.put.floating.arith.disc),\n",
    "                                                      asian.put.floating.geom.disc   = mean(summary.sim.df$asian.put.floating.geom.disc)\n",
    "                                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514b551",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
